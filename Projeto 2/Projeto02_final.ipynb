{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'intel'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rod_c\\Documents\\GitHub\\ciencia_dados\\Projeto 2\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dados = pd.ExcelFile('intel.xlsx',sep='.')\n",
    "dados.sheet_names\n",
    "Teste= dados.parse('Teste')\n",
    "Treinamento = dados.parse('Treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eliminando para Teste\n",
    "\n",
    "Teste = Teste.replace('#','',regex=True)\n",
    "Teste = Teste.replace(',','',regex=True)\n",
    "Teste = Teste.replace('()','',regex=True)\n",
    "Teste = Teste.replace('@','',regex=True)\n",
    "Teste = Teste.replace('rt','',regex=True)\n",
    "Teste = Teste.replace(':','',regex=True)\n",
    "Teste = Teste.replace('-','',regex=True)\n",
    "Teste = Teste.replace('https','',regex=True)\n",
    "Teste = Teste.replace('®','',regex=True)\n",
    "Teste = Teste.replace('!','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#eliminando para treinamento\n",
    "\n",
    "Treinamento = Treinamento.replace('#','',regex=True)\n",
    "Treinamento = Treinamento.replace(',','',regex=True)\n",
    "Treinamento = Treinamento.replace('()','',regex=True)\n",
    "Treinamento = Treinamento.replace('@','',regex=True)\n",
    "Treinamento = Treinamento.replace('rt','',regex=True)\n",
    "Treinamento = Treinamento.replace(':','',regex=True)\n",
    "Treinamento = Treinamento.replace('-','',regex=True)\n",
    "Treinamento = Treinamento.replace('!','',regex=True)\n",
    "#Treinamento = Treinamento.replace('\\n','',regex=True)\n",
    "Treinamento = Treinamento.replace('https','',regex=True)\n",
    "Treinamento = Treinamento.replace('®','',regex=True)\n",
    "#Treinamento = Treinamento.replace('.','',regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "110\n",
      "0.36666666666666664\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "lista = []\n",
    "R = 0\n",
    "I = 0 \n",
    "for values in Treinamento.Classificação:\n",
    "    lista.append(values.split())\n",
    "for i in lista:\n",
    "    if i == ['relevante']:\n",
    "        R +=1\n",
    "    else:\n",
    "        if i == ['irrelevante']:\n",
    "            I +=1\n",
    "#quantidade de irrelevantes\n",
    "print(I)\n",
    "#quantidade de relevantes\n",
    "print(R)\n",
    "\n",
    "#porcentagem de relevantes e irrelevanes\n",
    "relevante = R/300\n",
    "irrelevante = I/300\n",
    "print(relevante)\n",
    "print(irrelevante)\n",
    "\n",
    "rev_ = Treinamento[Treinamento.Classificação == 'relevante']\n",
    "irrev_ = Treinamento[Treinamento.Classificação == 'irrelevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treinamento\n",
    "\n",
    "treinamento_b = Treinamento.Treinamento\n",
    "classe = Treinamento.Classificação\n",
    "dict_pal = dict()\n",
    "for x in range(0, len(treinamento_b)):\n",
    "    situação = classe[x]\n",
    "    twt= treinamento_b[x].split()\n",
    "    for palavras in twt:\n",
    "        if palavras in dict_pal:\n",
    "            if situação == \"relevante\":\n",
    "                dict_pal[palavras][0] += 1\n",
    "            else:\n",
    "                dict_pal[palavras][1] += 1\n",
    "        else:\n",
    "            if situação == 'relevante':\n",
    "                dict_pal[palavras] = [1,0]\n",
    "            else:\n",
    "                dict_pal[palavras] = [0,1]\n",
    "#print(dict_pal)\n",
    "#print(len(dict_pal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1767\n",
      "3064\n"
     ]
    }
   ],
   "source": [
    "##Mostra a soma de todas as palavras dentro de relevante ou irrelevante\n",
    "\n",
    "resultado_bom = 0\n",
    "resultado_neutro = 0\n",
    "for values in dict_pal:\n",
    "    resultado_bom += dict_pal[values][0]\n",
    "    resultado_neutro += dict_pal[values][1]\n",
    "print(resultado_bom) #qunatidade de palavras relevante\n",
    "print(resultado_neutro) #qunatidade de palavras irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.527447651386531"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#porcentagem de cada palavra em relevante\n",
    "\n",
    "coluna_r = np.sum(rev_.Treinamento + '').split()\n",
    "coluna_r2 = pd.Series(coluna_r) \n",
    "# mostra uma tabela com a porcentagem de cada palavra em relevantes\n",
    "#print(coluna_r2.value_counts(' ')*100)\n",
    "# mostra uma tabela com a quantidade de cada palavra em relevantes\n",
    "#print(coluna_r.value_counts(''))\n",
    "\n",
    "\n",
    "#porcentagem para a palavra Intel dentro de relevantes\n",
    "coluna_r.count('intel')*100/(resultado_bom)\n",
    "#coluna = pd.Series(np.sum(Treinamento.Treinamento + '').split())\n",
    "#coluna.value_counts('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5365535248041775"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para contar separadamente cada palavra a linha de codico à baixo apresenta erro\n",
    "coluna_i =  pd.Series(np.sum(irrev_.Treinamento + '').split())\n",
    "#porcentagem de cada palavra em irrelevante (necessario separqar em duas partes para contar as palavras separadamente)\n",
    "coluna_i = np.sum(irrev_.Treinamento + '').split()\n",
    "coluna_i2 = pd.Series(coluna_i)\n",
    "#print(coluna_i2.value_counts(' ')*100)\n",
    "col = len(coluna_i)\n",
    "\n",
    "#porcentagem da palavra intel dentro de irrelevantes\n",
    "coluna_i.count('intel')*100/(resultado_neutro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.320316921335597]\n",
      "[0.97911227154047]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'relevante'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr1 = \"com\"\n",
    "\n",
    "# Função criada para sistematizar a classificação das frases, testados em um primeiro momento com apenas palavras\n",
    "\n",
    "def leitura (x):\n",
    "    frase = x.split(' ') # dividir a frase pelos espaços\n",
    "    relevante = []\n",
    "    irrelevante = [] \n",
    "    for e in range(len(frase)):\n",
    "\n",
    "        relevante.append(((coluna_r.count(frase[e])))*100/(resultado_bom))\n",
    "        irrelevante.append((coluna_i.count(frase[e]))*100/(resultado_neutro))\n",
    "        \n",
    "    print(relevante)\n",
    "    print(irrelevante)\n",
    "    probR = np.prod(relevante)\n",
    "    probIR = np.prod(irrelevante)\n",
    "    if probR > probIR:\n",
    "        return \"relevante\"\n",
    "    else:\n",
    "        return \"irrelevante\"\n",
    "\n",
    "leitura(\"com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Atribuindo todas as frases de arquivo execel Teste da coluna teste em uma lista, para futuramente utiliza-la na função Leitura\n",
    "lis =[]\n",
    "for values in Teste.Teste:\n",
    "    lis.append(values)\n",
    "\n",
    "# Mesma função utilizada no item anterior \n",
    "def leitura (x):\n",
    "    frase = x.split(' ') # dividir a frase pelos espaços\n",
    "    relevante = []\n",
    "    irrelevante = []\n",
    "    resultado=[]\n",
    "    for e in range(len(frase)):\n",
    "\n",
    "        relevante.append(((coluna_r.count(frase[e])))*100/(resultado_bom))\n",
    "        irrelevante.append((coluna_i.count(frase[e]))*100/(resultado_neutro))\n",
    "        \n",
    "    probR = np.prod(relevante)\n",
    "    probIR = np.prod(irrelevante)\n",
    "    if probR > probIR:\n",
    "        resultado.append(\"relevante\")\n",
    "        \n",
    "    else:\n",
    "        resultado.append(\"irrelevante\")\n",
    "    return resultado    \n",
    "\n",
    "# Criação de outra lista para armazenar o que foi retornado da função para as frases dentro de Lis\n",
    "computador=[]\n",
    "for e in lis:\n",
    "    x=leitura(e)\n",
    "    computador.append(x)\n",
    "\n",
    "\n",
    "# Código para contar a quantidade de irrelevantes e relevantes, mas não é necessário para os futuros resultados,\n",
    "#portanto está comentado\n",
    "\n",
    "#relevantes_v = 0\n",
    "#irrelevantes_v = 0\n",
    "#for e in lis:\n",
    "#    if leitura(e) == \"relevante\":\n",
    "#        relevaentes_v +=1\n",
    "#    if leitura(e) == \"irrelevante\":\n",
    "#        irrelevantes_v +=1\n",
    "#    print(leitura(e))\n",
    "#\n",
    "#print(relevaentes_v) #qunatidade de palavras relevantes\n",
    "#print(irrelevantes_v) #quantidade de palavras irrelevantes\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notebook gamer acer vx 5 intel core i5 7ª gera...</td>\n",
       "      <td>irrelevante</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lucains olha esse oq vc acha? //t.co/pla15u3gf9</td>\n",
       "      <td>irrelevante</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gostei de um vídeo youtube //t.co/hvurmglk6p f...</td>\n",
       "      <td>irrelevante</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sacolacheiax confira no magazine espacomall n...</td>\n",
       "      <td>irrelevante</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samsung anuncia mega fábrica e passa intel com...</td>\n",
       "      <td>irrelevante</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Classificação  \\\n",
       "0  notebook gamer acer vx 5 intel core i5 7ª gera...   irrelevante   \n",
       "1    lucains olha esse oq vc acha? //t.co/pla15u3gf9   irrelevante   \n",
       "2  gostei de um vídeo youtube //t.co/hvurmglk6p f...   irrelevante   \n",
       "3   sacolacheiax confira no magazine espacomall n...   irrelevante   \n",
       "4  samsung anuncia mega fábrica e passa intel com...   irrelevante   \n",
       "\n",
       "            pc  \n",
       "0  irrelevante  \n",
       "1  irrelevante  \n",
       "2  irrelevante  \n",
       "3  irrelevante  \n",
       "4  irrelevante  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtivemos um problema com a célula anterior, na tabela a baixo, na coluna pc, as palavras apareciam entre chaves \n",
    "flat_list =[]\n",
    "for sublist in abc:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)   \n",
    "# criando uma nova coluna em que o próprio programa declarou se a mensagem era releveante ou irrelevaente\n",
    "Teste['pc'] = pd.Series(flat_list)\n",
    "Teste.head()\n",
    "# o código acima foi utilizado para solucionar esse problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negativos verdadeiros    0.75\n",
       "negativos falsos         0.19\n",
       "positivos falsos         0.05\n",
       "positivos verdadeiros    0.01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = []\n",
    "\n",
    "for a in range(len(Teste.Teste)):\n",
    "    if Teste.Classificação[a] == 'relevante':\n",
    "        if Teste.pc[a] == 'relevante':\n",
    "            br.append('positivos verdadeiros')\n",
    "        if Teste.pc[a] == 'irrelevante':\n",
    "            br.append('negativos falsos')\n",
    "    elif Teste.Classificação[a] == 'irrelevante':\n",
    "        if Teste.pc[a] == 'irrelevante':\n",
    "            br.append('negativos verdadeiros')\n",
    "        if Teste.pc[a] == 'relevante':\n",
    "            br.append('positivos falsos')\n",
    "\n",
    "##\n",
    "\n",
    "#porcentagem das medidas:\n",
    "\n",
    "##\n",
    "porcentagem = pd.Series(br)\n",
    "hue= (porcentagem.value_counts())/200\n",
    "hue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Considerando os resultados obtidos podemos tirar algumas conclusões, tendo em vista a quantidade maior de Irrelevantes do que Relevantes, tanto em treinamento como em Teste, o numero de Negativos verdadeiros atingiu um acerto muito positivo. Porém ao analisarmos o que aconteceu no Treinamento, onde a a maioria das palavras era mais frequente em irrelevantes e que palavras específicas, por exemplo ótimo, horrível apareciam tão pouco que as frases para serem classificadas dependiam de outras menos representativas. Pensando no significado oposto aos das específicas, as palavras não representativas são as estão ambas representadas em irrelevantes como em relevantes, mas como na maioria dos casos são mais presentes em irrelevantes isso acarreta em uma chance bem maior do \"classificador automático\" dizer que as frases são irrelevantes. <br />\n",
    "\n",
    "Ressaltando o que foi dito no parágrafo anterior, ao analisarmos as outras classificações e e suas porcentagens, negativos falsos 0.19%, positivos falsos 0.05%, positivos verdadeiros 0.01%, especialmente os negativos falsos e os positivos falsos observamos que 95% dois positivos classificados manualmente foram considerados negativos e apenas 6,66% dos negativos classificados manualmente foram considerados positivos. Isso apenas reforça o primeiro parágrafo indicando uma forte tendencia das frases serem classificadas como Irrelevantes. Porém isso não é um aspecto apenas negativos, pode estar fortemente atrelado e pequena quantidade de palavras pertencente fortemente a apenas a relevante, por exemplo. Para um futuro plano de expansão concluimos que estes 76% de acerto obtido podem aumentar com o aumento de tweets classificados manualmente, implicando diretamente na maior aparição destas palavras representativas aumentando ainda mais a oporcentagem de acertos e principalmente classificando corretamente cada vez mais frases relevantes.<br />\n",
    "\n",
    "As mensagens de dupla negação e sarcasmos foram reconhecidas com a classificação manual, mas com a automática podem ter passado desapercebidas pois dependem apenas da probablidade das palavras que a compõem, para uma futura implementação considerar apenas essas palavras e calcular a probabilidade de cada palavra estarem dentro deste tipo de frase, mas para isso seria necessário uma amosta para obter um número significativo de duplo negativo e sarcasmo.<br />\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
